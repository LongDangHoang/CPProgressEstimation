{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from itertools import chain\n",
    "from pathlib import *\n",
    "from math import ceil\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from helper import *\n",
    "from tree_weight import *\n",
    "from time import time\n",
    "from main import make_graph_from_tree\n",
    "\n",
    "from typing import List\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'graphs/'\n",
    "tree = 'benchmark_models/league/trees/model15-4-3.sqlite'\n",
    "info_df = to_df(tree, 'info').set_index('NodeID')\n",
    "nodes_df = to_df(tree, 'nodes').set_index('NodeID')\n",
    "# # nodes_df['Label'].str.split(' ', expand=True)[1].unique()\n",
    "# a = nodes_df[nodes_df['Label'] != '']['Label'].str.split(' ', expand=True)[0]\n",
    "# # a\n",
    "# (fig, ax), nodes_df, cum_sums = \\\n",
    "#     make_graph_from_tree(image_folder, tree, \n",
    "#     schemes=[\n",
    "#         uniform_scheme, \n",
    "#         domain_scheme, \n",
    "#         searchSpace_scheme\n",
    "#     ],\n",
    "#     write_to_sqlite=False)\n",
    "\n",
    "# if 'NodeWeight' in nodes_df.columns:\n",
    "#     nodes_df = nodes_df.rename(columns={'NodeWeight': 'UniformNodeWeight'})\n",
    "#     engine = create_engine('sqlite:///' + tree)\n",
    "#     write_df = nodes_df.reset_index()\n",
    "#     write_df.to_sql('Nodes', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the variable with no intersection\n",
    "# no goods domains are unreliable (one or more variable should have a null domain)\n",
    "# but the split variable's domain should still be reliable (?)\n",
    "# some split labels are not appearing in the domains and vice versa due to the domains outputing\n",
    "# only certain names in flatzinc, and some variables are never split on but filled by \n",
    "# propogation\n",
    "\n",
    "def pairwise_diff(lst):\n",
    "    return len(set(lst)) == len(lst)\n",
    "\n",
    "def is_unequal_split(nodes_df, children_idx):    \n",
    "    return set(nodes_df.loc[children_idx, 'Label']\\\n",
    "                   .str.split(' ', expand=True)[1]\\\n",
    "                   .unique())\\\n",
    "        == set(['=', '!='])\n",
    "\n",
    "def has_no_split_children(nodes_df, par_idx):\n",
    "    return nodes_df[nodes_df['ParentID'] == par_idx]['Status'].isin({2}).sum() == 0\n",
    "\n",
    "\n",
    "def find_split_variable(par_idx, nodes_df, info_df, mappings: dict={}):\n",
    "    # mappings between label_name -> info_name\n",
    "    children_idx = nodes_df[nodes_df['ParentID'] == par_idx].index\n",
    "    is_skipped = nodes_df[nodes_df['ParentID'] == par_idx]['Status'] == 3\n",
    "    cands = []\n",
    "    \n",
    "    if nodes_df.loc[par_idx, 'Status'] != 2 or len(children_idx) == 0 or is_skipped.sum() == len(children_idx):\n",
    "        return []\n",
    "    else:\n",
    "        label_var = nodes_df.loc[children_idx[0], 'Label'].split(' ')[0]\n",
    "        par_domain = parse_info_string(info_df.loc[par_idx, 'Info'])\n",
    "        if label_var in mappings:\n",
    "            return [mappings[label_var]]\n",
    "    \n",
    "    if is_skipped.sum() > 0:\n",
    "        # we have only one node to rely on to get the split variable\n",
    "        child_idx = children_idx[~is_skipped][0]\n",
    "        child_domain = parse_info_string(info_df.loc[child_idx, 'Info'])\n",
    "        split_val = int(nodes_df.loc[child_idx, 'Label'].split('=')[1])\n",
    "        \n",
    "        for variable in par_domain:\n",
    "            rule_1 = variable in child_domain\n",
    "            if '!' in nodes_df.loc[child_idx, 'Label']:\n",
    "                # case 1: label != split_val\n",
    "                rule_2 = split_val not in child_domain[variable] and \\\n",
    "                         child_domain[variable].union({split_val}) == par_domain[variable]\n",
    "            else:\n",
    "                # case 2: label = split_val\n",
    "                rule_2 = {split_val} == child_domain[variable] and split_val in par_domain[variable]\n",
    "            if rule_1 and rule_2 and variable not in mappings:\n",
    "                cands.append(variable)\n",
    "                \n",
    "    else:\n",
    "\n",
    "        split_vals = nodes_df.loc[children_idx, 'Label'].str.split('=', expand=True)[1].astype(int).unique().flatten()\n",
    "        children_domain = [\n",
    "            parse_info_string(info_df.loc[child_id, 'Info']) for child_id in children_idx\n",
    "        ]\n",
    "\n",
    "        # children domain may include domains of no-goods which are unreliable\n",
    "        # for now we ignore this thorny problem\n",
    "\n",
    "        if not is_unequal_split(nodes_df, children_idx):\n",
    "            assert len(split_vals) == len(children_idx)\n",
    "            for variable in par_domain:\n",
    "                # each child should have a label = split_value\n",
    "                rule_1 = all([children_domain[i][variable] == {split_vals[i]} for i in range(len(children_domain))])\n",
    "                rule_2 = set.union(*[children_domain[i][variable] for i in range(len(children_domain))])\\\n",
    "                            == par_domain[variable]\n",
    "                rule_3 = pairwise_diff(split_vals)\n",
    "\n",
    "                if rule_1 and rule_2 and rule_3:\n",
    "                    cands.append(variable)      \n",
    "\n",
    "        else:\n",
    "            assert len(children_domain) == 2\n",
    "            assert len(split_vals) == 1\n",
    "            split_val = split_vals[0]\n",
    "            for variable in par_domain:\n",
    "                child_1, child_2 = children_domain\n",
    "\n",
    "                # case 1\n",
    "                rule_1 = ({split_val} == child_1[variable]) and (split_val not in child_2[variable])\n",
    "                rule_2 = child_2[variable].union({split_val}) == par_domain[variable]\n",
    "                # case 2\n",
    "                rule_3 = {split_val} == child_2[variable] and split_val not in child_1[variable]\n",
    "                rule_4 = child_1[variable].union({split_val}) == par_domain[variable]\n",
    "\n",
    "                if (rule_1 and rule_2) or (rule_3 and rule_4):\n",
    "                    cands.append(variable)\n",
    "\n",
    "    # filter by not set in par\n",
    "    cands = [name for name in cands if not len(par_domain[name]) == 1]\n",
    "                    \n",
    "    if len(cands) == 1:\n",
    "        mappings[label_var] = cands[0]\n",
    "        mappings[cands[0]] = label_var\n",
    "    return cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {}\n",
    "all_split_vars = nodes_df['Label'].str.split(' ', expand=True)[0].unique()\n",
    "all_split_vars = set(all_split_vars) - set([''])\n",
    "\n",
    "for node_idx in range(nodes_df.shape[0]):\n",
    "#     if nodes_df.loc[node_idx, 'Status'] != 2:\n",
    "#         print('Not a parent node')\n",
    "#     else:\n",
    "    cands = find_split_variable(node_idx, nodes_df, info_df, mappings)\n",
    "    if len(cands) > 2:\n",
    "        import pdb; pdb.set_trace()\n",
    "\n",
    "    if len(mappings)// 2 == len(all_split_vars):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assign_to[1]': 'X_INTRODUCED_3_',\n",
       " 'X_INTRODUCED_3_': 'assign_to[1]',\n",
       " 'assign_to[2]': 'X_INTRODUCED_4_',\n",
       " 'X_INTRODUCED_4_': 'assign_to[2]',\n",
       " 'assign_to[3]': 'X_INTRODUCED_5_',\n",
       " 'X_INTRODUCED_5_': 'assign_to[3]',\n",
       " 'assign_to[4]': 'X_INTRODUCED_6_',\n",
       " 'X_INTRODUCED_6_': 'assign_to[4]',\n",
       " 'assign_to[5]': 'X_INTRODUCED_7_',\n",
       " 'X_INTRODUCED_7_': 'assign_to[5]',\n",
       " 'assign_to[6]': 'X_INTRODUCED_8_',\n",
       " 'X_INTRODUCED_8_': 'assign_to[6]',\n",
       " 'assign_to[7]': 'X_INTRODUCED_9_',\n",
       " 'X_INTRODUCED_9_': 'assign_to[7]',\n",
       " 'assign_to[8]': 'X_INTRODUCED_10_',\n",
       " 'X_INTRODUCED_10_': 'assign_to[8]',\n",
       " 'assign_to[9]': 'X_INTRODUCED_11_',\n",
       " 'X_INTRODUCED_11_': 'assign_to[9]',\n",
       " 'assign_to[12]': 'X_INTRODUCED_14_',\n",
       " 'X_INTRODUCED_14_': 'assign_to[12]',\n",
       " 'assign_to[13]': 'X_INTRODUCED_15_',\n",
       " 'X_INTRODUCED_15_': 'assign_to[13]',\n",
       " 'assign_to[14]': 'X_INTRODUCED_16_',\n",
       " 'X_INTRODUCED_16_': 'assign_to[14]',\n",
       " 'assign_to[15]': 'X_INTRODUCED_17_',\n",
       " 'X_INTRODUCED_17_': 'assign_to[15]'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assign_to[10]',\n",
       " 'assign_to[12]',\n",
       " 'assign_to[13]',\n",
       " 'assign_to[14]',\n",
       " 'assign_to[15]',\n",
       " 'assign_to[1]',\n",
       " 'assign_to[2]',\n",
       " 'assign_to[3]',\n",
       " 'assign_to[4]',\n",
       " 'assign_to[5]',\n",
       " 'assign_to[6]',\n",
       " 'assign_to[7]',\n",
       " 'assign_to[8]',\n",
       " 'assign_to[9]',\n",
       " 'rank_diff[1]',\n",
       " 'rank_diff[2]'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_split_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([19], dtype='int64', name='NodeID')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = '''{\n",
    "\t\"domains\": \"var 49992..89992: obj;\n",
    "var int: X_INTRODUCED_3_ = 3;\n",
    "var int: X_INTRODUCED_4_ = 3;\n",
    "var int: X_INTRODUCED_5_ = 3;\n",
    "var int: X_INTRODUCED_6_ = 3;\n",
    "var int: X_INTRODUCED_7_ = 3;\n",
    "var int: X_INTRODUCED_8_ = 2;\n",
    "var int: X_INTRODUCED_9_ = 2;\n",
    "var int: X_INTRODUCED_10_ = 2;\n",
    "var int: X_INTRODUCED_11_ = 2;\n",
    "var int: X_INTRODUCED_12_ = 2;\n",
    "var int: X_INTRODUCED_13_ = 1;\n",
    "var int: X_INTRODUCED_14_ = 1;\n",
    "var int: X_INTRODUCED_15_ = 1;\n",
    "var int: X_INTRODUCED_16_ = 1;\n",
    "var int: X_INTRODUCED_17_ = 1;\n",
    "var int: X_INTRODUCED_39_ = 2;\n",
    "var int: X_INTRODUCED_40_ = 3;\n",
    "var int: X_INTRODUCED_41_ = 3;\n",
    "var int: X_INTRODUCED_18_ = 4;\n",
    "var int: X_INTRODUCED_19_ = 4;\n",
    "var int: X_INTRODUCED_20_ = 4;\n",
    "var 1..3: X_INTRODUCED_21_;\n",
    "var 1..3: X_INTRODUCED_22_;\n",
    "var int: X_INTRODUCED_23_ = 1;\n",
    "\"\n",
    "}'''\n",
    "info_df[info_df['Info'] == x].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df.loc[[1, 2], 'Label'].str.split('=').e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df[nodes_df['ParentID'] == node_idx]['Label'].str.split(' ', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df['Info'].apply(parse_info_string).apply(lambda x: len(x)).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NOTES\n",
    "\n",
    "# some children's domains are larger than parent's domain, but these are dead ends that are not updated to be null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df.reset_index().reindex(columns=['NodeID', 'ParentID', 'Alternative', 'NKids', 'Status', 'Label'] + nodes_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///' + tree)\n",
    "write_df = nodes_df.reset_index().drop(columns='NodeWeight')\n",
    "write_df.to_sql('Nodes', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Time taken for apply method: \", time_1)\n",
    "print(\"Time taken for series method: \", time_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nodes_df['\n",
    "- total time: 20min\n",
    "- make_dfs_ordering: 3m30s\n",
    "- load info_df: 365ms\n",
    "- load nodes_df: 404ms\n",
    "- copy nodes_df: 7.96ms\n",
    "- assign weights to nodes_df: 7min30s\n",
    "- assign weights to test_df: 12min26s\n",
    "- get_cum_weights for nodes_df: 156ms\n",
    "- get_cum_weights for test_df: 125ms\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
