{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.sparse as sparse\n",
    "from test import *\n",
    "\n",
    "from itertools import chain\n",
    "from pathlib import *\n",
    "from math import ceil\n",
    "from sqlalchemy import create_engine\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "from test import *\n",
    "from helper import *\n",
    "from tree_weight import *\n",
    "from time import time\n",
    "from main import make_graph_from_tree\n",
    "from multiprocessing import *\n",
    "\n",
    "from typing import List\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandarallel.initialize(nb_workers=cpu_count() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(322477, 12)\n"
     ]
    }
   ],
   "source": [
    "image_folder = 'graphs/'\n",
    "tree = 'benchmark_models/grid-colouring/trees/4_8.sqlite'\n",
    "info_df = to_df(tree, 'info').set_index('NodeID')\n",
    "nodes_df = to_df(tree, 'nodes').set_index('NodeID')\n",
    "valid_df = nodes_df[nodes_df['Status'] != 3]\n",
    "\n",
    "print(nodes_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dfs_ordering_new(nodes_df: pd.DataFrame) -> list:\n",
    "    \"\"\"\n",
    "    Return list of nodeids in the order they were entered by\n",
    "    the depth-first search algorithm.\n",
    "\n",
    "    \"\"\"\n",
    "    valid_df = nodes_df[nodes_df['Status'] != 3]\n",
    "    dfs_ordering = [0]\n",
    "    boundary = [valid_df[(valid_df['ParentID'] == 0) & (valid_df['Status'] != 3)]\\\n",
    "                .sort_values('Alternative', ascending=False).index.to_list()]\n",
    "\n",
    "    # run simulated dfs on tree\n",
    "    while len(boundary) > 0:\n",
    "        if len(boundary[-1]) == 0:\n",
    "            boundary.pop()\n",
    "            continue\n",
    "        \n",
    "        nxt = boundary[-1].pop()\n",
    "        dfs_ordering.append(nxt)\n",
    "        boundary.append(valid_df[(valid_df['ParentID'] == nxt) & (valid_df['Status'] != 3)]\\\n",
    "                             .sort_values('Alternative', ascending=False).index.to_list())\n",
    "\n",
    "    assert set(dfs_ordering) == (set(nodes_df.index) - set(nodes_df[nodes_df['Status'] == 3].index))\n",
    "    return dfs_ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_subtree_size_new(nodes_df):\n",
    "    valid_df = nodes_df[nodes_df['Status'] != 3]\n",
    "    valid_df['SubtreeSize'] = 0\n",
    "    \n",
    "    start = valid_df[valid_df['Status'].isin({0, 1})] # start with children\n",
    "    valid_df.loc[start.index, 'SubtreeSize'] = 1\n",
    "    while 0 != start.index[0]:\n",
    "        parent_idx = valid_df.loc[start.index, 'ParentID'].unique()\n",
    "        valid_df.loc[parent_idx, 'SubtreeSize'] = valid_df.loc[start.index,:].groupby(['ParentID']).sum()['SubtreeSize']\n",
    "        start = valid_df.loc[parent_idx, :]\n",
    "        \n",
    "    return valid_df['SubtreeSize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.DataFrame.copy(nodes_df[nodes_df['Status'] != 3])\n",
    "valid_df['SubtreeSize'] = np.nan\n",
    "valid_df['HasNotSubtreeSize'] = True\n",
    "\n",
    "start = valid_df[valid_df['Status'].isin({0, 1})] # start with leaves\n",
    "valid_df.loc[start.index, 'SubtreeSize'] = 1\n",
    "valid_df.loc[start.index, 'HasNotSubtreeSize'] = False\n",
    "\n",
    "while valid_df['HasNotSubtreeSize'].sum() > 0:\n",
    "    parent_idx = np.unique(valid_df.loc[start.index, 'ParentID'].values)\n",
    "    # filter out parent with unexplored children\n",
    "    parent_idx = valid_df.loc[valid_df['ParentID'].isin(parent_idx)]\\\n",
    "                    .groupby(['ParentID'])\\\n",
    "                    .sum()['HasNotSubtreeSize'] # parent_index along with count of nodes without subtreesize\n",
    "    parent_idx = parent_idx[parent_idx == 0].index\n",
    "    valid_df.loc[parent_idx, 'SubtreeSize'] = 1 + valid_df[valid_df['ParentID'].isin(parent_idx)].groupby(['ParentID']).sum()['SubtreeSize']\n",
    "    valid_df.loc[parent_idx, 'HasNotSubtreeSize'] = False\n",
    "    start = valid_df.loc[parent_idx, :]\n",
    "    \n",
    "nodes_df.loc[:, 'SubtreeSize'] = valid_df['SubtreeSize']\n",
    "nodes_df.loc[nodes_df['SubtreeSize'].isna(), 'SubtreeSize'] = 0\n",
    "nodes_df.loc[:, 'SubtreeSize'] = nodes_df['SubtreeSize'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = nodes_df['SubtreeSize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(nodes_df['SubtreeSize'] != orig).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0.9\n",
    "res_df = pd.DataFrame.copy(valid_df.iloc[1:, :])\n",
    "res_df['Weight'] = np.random.random(res_df.shape[0])\n",
    "parent_mean = res_df.groupby('ParentID').mean()['Weight']\n",
    "parent_count = res_df.groupby('ParentID').count()['Weight']\n",
    "\n",
    "# index swap\n",
    "res_df = res_df.reset_index().set_index('ParentID')\n",
    "res_df.loc[:, 'Mean'] = parent_mean\n",
    "res_df.loc[:, 'Count'] = parent_count\n",
    "res_df = res_df.reset_index().set_index('NodeID')\n",
    "res_df.loc[:, 'Weight'] = res_df['Weight'] - res_df['Mean'] + k / res_df['Count']\n",
    "j = res_df.groupby(['ParentID']).sum()['Weight']\n",
    "j[abs(j - k) > 1e-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = valid_df[['ParentID', 'HasUnequalSplit']].reset_index().set_index('ParentID').iloc[1:,:]\n",
    "weights.loc[:, 'ParentDomainSize'] = parent_domain_size\n",
    "weights = weights.reset_index().set_index('NodeID')\n",
    "weights['Weight'] = 1 / weights['ParentDomainSize'] + weights['HasUnequalSplit'] * (1 - 2 / weights['ParentDomainSize'])\n",
    "weights.drop(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeSplitVarDomain = domains.iloc[1:,:].parallel_apply(lambda r: len(r['Info'][r['label']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains['parentLabel'] = get_parent_column('label', domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
